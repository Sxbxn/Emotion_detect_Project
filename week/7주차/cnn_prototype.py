# -*- coding: utf-8 -*-
"""cnn_prototype.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VkGzHSHBHbCldq6M7NYTEw3xxcf96DIu

# CNN 설계
"""

import torch
import torch.nn as nn
import torchvision
import torch.optim as optim
import torch.nn.functional as F
from torchvision import transforms, datasets, models
from torchvision.utils import make_grid
import os
from matplotlib import pyplot as plt
from PIL import Image
import numpy as np

USE_CUDA = torch.cuda.is_available()
DEVICE = torch.device("cuda" if USE_CUDA else "cpu")
print(DEVICE)

from google.colab import drive
drive.mount('/content/drive')

# !pip install kaggle --upgrade
# os.environ['KAGGLE_USERNAME'] = 'jungyuchoi'
# os.environ['KAGGLE_KEY'] = '9431599f2458bdba977477e62d1dd272'
# !kaggle datasets download -d ananthu017/emotion-detection-fer
# !unzip '*.zip'

!ls
torch.cuda.empty_cache()
import gc
gc.collect()

"""## 하이퍼파라미터 """

EPOCHS     = 50
BATCH_SIZE = 200
MAX_LR = 0.008

"""## 데이터셋 불러오기"""

trans = transforms.Compose([
                            transforms.Grayscale(),
                            # transforms.RandomHorizontalFlip(),
                            transforms.RandomRotation(30),
                            transforms.ToTensor(),
                            transforms.Normalize((0.5,), (0.5,))])

train_data = torchvision.datasets.ImageFolder(root='./train', transform=trans)
test_data = torchvision.datasets.ImageFolder(root='./test', transform=trans)

train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = BATCH_SIZE, shuffle = True)
test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = BATCH_SIZE, shuffle = True)

classes = ['neutral', 'fearful', 'sad', 'happy', 'surprised', 'angry', 'disgusted']

dataiter = iter(train_loader)
images, labels = dataiter.next()
print(images.shape)
img = Image.open('./train/angry/im1.png')
plt.imshow(np.asarray(img))
print(labels)

"""## 모델


"""

# 미리 훈련된 ResNet 모델을 다운로드하고 불러옴
# torchvision.models 참고

import torchvision.models as models

# model = models.resnet50(pretrained=True)
# print(model) # 불러온 모델 구조 확인

class Model(nn.Module):
    def __init__(self):
      super(Model, self).__init__()
      self.conv1 = nn.Conv2d(1, 16, 3)
      self.conv2 = nn.Conv2d(16, 32, 3)
      self.conv3 = nn.Conv2d(32, 64, 3)
      self.conv4 = nn.Conv2d(64, 32, 3)
      self.fc1 = nn.Linear(2048, 1024)
      self.fc2 = nn.Linear(1024, 128)
      self.fc3 = nn.Linear(128, 7)
      self.batch_norm_16 = nn.BatchNorm2d(16)
      self.batch_norm_32 = nn.BatchNorm2d(32)
      self.batch_norm_64 = nn.BatchNorm2d(64)
      self.drop_out = nn.Dropout2d(p=0.3)

    def forward(self, x):
      
      x = F.relu(self.batch_norm_16(self.conv1(x)))
      x = F.relu(self.drop_out(F.max_pool2d(self.batch_norm_32(self.conv2(x)), 2)))
      x = F.relu(self.drop_out(F.max_pool2d(self.batch_norm_64(self.conv3(x)), 2)))
      x = F.relu(self.drop_out(self.batch_norm_32(self.conv4(x))))
      x = x.view(-1, 2048)

      x = F.relu(self.drop_out(self.fc1(x)))
      x = F.relu(self.drop_out(self.fc2(x)))
      x = self.fc3(x)

      return x

model = Model()

"""## 준비"""

model.to(DEVICE)
model.load_state_dict(torch.load('/content/drive/MyDrive/model/model.pt'))
optimizer = optim.Adam(model.parameters(), lr=MAX_LR)
scheduler = optim.lr_scheduler.OneCycleLR(optimizer, MAX_LR, epochs=EPOCHS, steps_per_epoch=len(train_loader))

"""## 학습하기"""

def train(model, train_loader, optimizer, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(DEVICE), target.to(DEVICE)
        optimizer.zero_grad()
        output = model(data)
        loss = F.cross_entropy(output, target)
        loss.backward()
        optimizer.step()

"""## 테스트하기"""

def evaluate(model, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(DEVICE), target.to(DEVICE)
            output = model(data)

            # 배치 오차를 합산
            test_loss += F.cross_entropy(output, target,
                                         reduction='sum').item()

            # 가장 높은 값을 가진 인덱스가 바로 예측값
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)
    test_accuracy = 100. * correct / len(test_loader.dataset)
    return test_loss, test_accuracy

# !cd /content/model

# torch.save(model.state_dict(), "/content/drive/MyDrive/model/model.pt")

"""## 학습"""

loss = []
accuracy = []
for epoch in range(1, EPOCHS + 1):
    train(model, train_loader, optimizer, epoch)
    scheduler.step()
    test_loss, test_accuracy = evaluate(model, test_loader)
    
    loss.append(test_loss)
    accuracy.append(test_accuracy)
    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(
          epoch, test_loss, test_accuracy))
plt.plot(loss)
plt.plot(accuracy)
plt.ylim(0, 100)
plt.xlabel('Epoch')
plt.ylabel('Accuracy')

torch.save(model.state_dict(), "/content/drive/MyDrive/model/model_rotate.pt")